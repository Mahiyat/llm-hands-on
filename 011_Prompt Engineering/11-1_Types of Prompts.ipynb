{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Required Libraries",
   "id": "27f43b8ab9155951"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-17T16:47:18.008199Z",
     "start_time": "2024-10-17T16:47:17.586455Z"
    }
   },
   "source": [
    "import ollama\n",
    "from IPython.display import display, Markdown"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* ollama: This library provides access to Llama models for text generation.\n",
    "* IPython.display: This allows for displaying formatted outputs in Markdown."
   ],
   "id": "eb66ba142cc59943"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Zero-Shot Prompting Example: Generating a Response for Book Recommendations",
   "id": "c0f41a949de904de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:47:27.140362Z",
     "start_time": "2024-10-17T16:47:18.012210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response1 = ollama.generate(\n",
    "    model=\"llama3.2\",\n",
    "    prompt=\"Can you recommend me some Machine Learning books?\",\n",
    "    options={\n",
    "        \"seed\": 42,\n",
    "        \"temperature\": 0.5,\n",
    "    }\n",
    ")\n",
    "display(Markdown(response1['response']))"
   ],
   "id": "343322593eea5f2c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Here are some highly recommended machine learning books, covering a range of topics and skill levels:\n\n**Beginner-friendly books**\n\n1. **\"Python Machine Learning\" by Sebastian Raschka**: A comprehensive guide to machine learning with Python.\n2. **\"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron**: A practical introduction to machine learning with popular libraries.\n3. **\"Machine Learning Crash Course\" by Michael I. Jordan**: A concise overview of the field, covering key concepts and techniques.\n\n**Intermediate-level books**\n\n1. **\"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville**: A comprehensive guide to deep learning, including neural networks and convolutional networks.\n2. **\"Pattern Recognition and Machine Learning\" by Christopher M. Bishop**: A detailed introduction to machine learning, covering topics like linear regression, decision trees, and clustering.\n3. **\"Natural Language Processing (almost) from Scratch\" by Collobert et al.**: A practical guide to NLP, covering topics like text processing, sentiment analysis, and topic modeling.\n\n**Advanced-level books**\n\n1. **\"Pattern Recognition and Machine Learning\" by Christopher M. Bishop**: A more advanced version of the book mentioned earlier.\n2. **\"Deep Learning: A Practitioner's Approach\" by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton**: A detailed guide to deep learning, covering topics like convolutional networks and recurrent networks.\n3. **\"Learning from Data\" by David M. Blei, John D. Lafferty, and Tommi Jaakkola**: A comprehensive introduction to machine learning, covering topics like Bayesian inference, probabilistic graphical models, and Markov chain Monte Carlo methods.\n\n**Specialized books**\n\n1. **\"Reinforcement Learning: An Introduction\" by Richard S. Sutton and Andrew G. Barto**: A detailed guide to reinforcement learning, covering topics like Q-learning, SARSA, and policy gradients.\n2. **\"Computer Vision: Algorithms and Applications\" by Richard Szeliski**: A comprehensive introduction to computer vision, covering topics like image processing, object recognition, and tracking.\n3. **\"Natural Language Processing (NLP) with Python\" by Steven Bird, Ewan Klein, and Edward Loper**: A practical guide to NLP, covering topics like text processing, sentiment analysis, and topic modeling.\n\nThese books are just a few examples of the many great machine learning resources available. I hope you find something that interests you!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "**Code Explanation**\n",
    "* ollama.generate(): Calls the Llama model \"llama3.2\" to generate a response based on the provided prompt.\n",
    "* Prompt: \"Can you recommend me some Machine Learning books?\" asks for book recommendations on Machine Learning.\n",
    "* Options:\n",
    "    * \"seed\": 42: Ensures reproducibility of results by setting a fixed seed for randomization.\n",
    "    * \"temperature\": 0.5: Controls the randomness of responses, where a lower temperature makes outputs more deterministic.\n",
    "* display(Markdown()): Displays the generated response in Markdown format for easier reading."
   ],
   "id": "53319c5020e06678"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## One-Shot Prompting Example: Generating a Response for Arithmetic Calculation",
   "id": "88251adda26345b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:47:27.578860Z",
     "start_time": "2024-10-17T16:47:27.208424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response2 = ollama.generate(\n",
    "    model=\"llama3.2\",\n",
    "    prompt=\"\"\"\n",
    "    Add two numbers and give me the result. An example is provided below:\n",
    "    1+1=2\n",
    "    \n",
    "    Now give me the result of the following:\n",
    "    3+7=\n",
    "    \"\"\",\n",
    "    options={\n",
    "        \"seed\": 42,\n",
    "        \"temperature\": 0.5,\n",
    "    }\n",
    ")\n",
    "display(Markdown(response2['response']))"
   ],
   "id": "a280ca32a14ad65d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "The result of 3 + 7 is:\n\n10"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "**Code Explanation**\n",
    "* Prompt: Provides an example arithmetic operation (1+1=2) and then asks the model to solve a similar equation (3+7=).\n",
    "* Options: Same as before, using a seed of 42 and a temperature of 0.5 for consistency in the output.\n",
    "* display(Markdown()): Displays the result in Markdown format."
   ],
   "id": "80a084ed772302"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Few-Shot Prompting Example: Generating a Sentiment Analysis Response",
   "id": "e3e19a694e8a54f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:47:28.807900Z",
     "start_time": "2024-10-17T16:47:27.586698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response3 = ollama.generate(\n",
    "    model=\"llama3.2\",\n",
    "    prompt=\"\"\"\n",
    "    Provide me with the sentiment of the given employee performance review. Some examples are provided below:\n",
    "    You are doing a really great job! : Positive\n",
    "    Need to focus more on pager duty: Negative\n",
    "    Bravo Alice! Keep up the good work: Positive\n",
    "    \n",
    "    Now give me the sentiment of the following:\n",
    "    Why do we always have dissatisfied customers? I need to you to look into the matter seriously:\n",
    "    \"\"\",\n",
    "    options={\n",
    "        \"seed\": 42,\n",
    "        \"temperature\": 0.5,\n",
    "    }\n",
    ")\n",
    "display(Markdown(response3['response']))"
   ],
   "id": "4f525fceb273b0b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "The sentiment of the given employee performance review is:\n\nNegative\n\nAlthough the tone is somewhat formal and professional, the phrase \"I need to look into the matter seriously\" implies a sense of concern or criticism, suggesting that there are issues with customer satisfaction that need to be addressed. The overall tone is not encouraging or supportive, which indicates a negative sentiment."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "**Code Explanation**\n",
    "* Prompt: This one includes examples of employee performance reviews with sentiment labels and asks the model to determine the sentiment of a new review.\n",
    "* Options: Same as before.\n",
    "* display(Markdown()): Shows the sentiment classification in Markdown."
   ],
   "id": "8175b05b2854dfad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Chain-of-Thought Prompting Example: Generating a Response for Dividing Treats Among Children",
   "id": "9f467cfa1ddd2c02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:47:31.892069Z",
     "start_time": "2024-10-17T16:47:28.815803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response4 = ollama.generate(\n",
    "    model=\"llama3.2\",\n",
    "    prompt=\"\"\"\n",
    "    There are 12 chocolates and 16 cupcakes. How will you distribute the treats equally among 4 children?\n",
    "    1. Start with the total number of chocolates\n",
    "    2. Divide the total number of chocolates by the total number of children\n",
    "    3. Provide the number of chocolates each child will get\n",
    "    4. Next continue with the total number of cupcakes\n",
    "    5. Divide the total number of cupcakes by the total number of children\n",
    "    6. Provide the number of cupcakes each child will get\n",
    "    7. Finally provide the number of chocolates and number of cupcakes each child will get as the answer\n",
    "    \"\"\",\n",
    "    options={\n",
    "        \"seed\": 42,\n",
    "        \"temperature\": 0.5,\n",
    "    }\n",
    ")\n",
    "display(Markdown(response4['response']))"
   ],
   "id": "106d61afdcbcf186",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "To distribute the treats equally among 4 children, I would follow steps 1-7:\n\n1. Start with the total number of chocolates: There are 12 chocolates.\n2. Divide the total number of chocolates by the total number of children: 12 ÷ 4 = 3\n3. Provide the number of chocolates each child will get: Each child will get 3 chocolates.\n\nNext, continue with the total number of cupcakes:\n\n4. Next continue with the total number of cupcakes: There are 16 cupcakes.\n5. Divide the total number of cupcakes by the total number of children: 16 ÷ 4 = 4\n6. Provide the number of cupcakes each child will get: Each child will get 4 cupcakes.\n\nFinally, provide the number of chocolates and number of cupcakes each child will get as the answer:\n\nEach child will get 3 chocolates and 4 cupcakes."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------\n",
    "**Code Explanation**\n",
    "* Prompt: Provides step-by-step instructions for dividing 12 chocolates and 16 cupcakes equally among 4 children, guiding the model to calculate how many each child receives.\n",
    "* Options: Maintains a controlled randomness and reproducibility as before.\n",
    "* display(Markdown()): Shows the final result of the distribution in a readable format."
   ],
   "id": "73cdc0a94bd48ac6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "This code demonstrates the examples of different types of prompting. A brief summary of the different types of prompts are as follows:\n",
    "* Zero-Shot Prompting: Asking for book recommendations without any example.\n",
    "* One-Shot Prompting: Solving an addition problem with one example as a reference.\n",
    "* Few-Shot Prompting: Performing sentiment analysis with multiple examples to clarify the task.\n",
    "* Chain-of-Thought Prompting: Distributing treats among children by listing each logical step for problem-solving.\n",
    "\n",
    "These different prompting strategies help shape the model’s response by guiding it to understand the context, format, and reasoning required."
   ],
   "id": "fd2de2b32ee47182"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
