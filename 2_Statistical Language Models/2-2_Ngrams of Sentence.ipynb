{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+ahUWlUePVgR4YrAMhZDw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Install Library**"],"metadata":{"id":"SuOrQNH29UfA"}},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcRauyly0PZn","executionInfo":{"status":"ok","timestamp":1720517405366,"user_tz":-360,"elapsed":11842,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"bb3f5a9a-cd7a-446d-dfe9-2b881f19f4b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"]}]},{"cell_type":"markdown","source":["The command above installs the nltk library, which is a powerful toolkit for working with human language data."],"metadata":{"id":"p1Pb_Yio_RoE"}},{"cell_type":"markdown","source":["**Import Library and Download Required nltk Data**\n","\n","\n","\n"],"metadata":{"id":"4sHqP7Bx9woT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7UFOCg8oyCq6","executionInfo":{"status":"ok","timestamp":1720517406773,"user_tz":-360,"elapsed":1409,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"7ffce7e2-3fe1-42c8-f8a2-59bcfb786868"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["import nltk\n","from nltk.util import ngrams\n","nltk.download('punkt')"]},{"cell_type":"markdown","source":["\n","*   import nltk: This imports the nltk library.\n","*   from nltk.util import ngrams: This imports the ngrams function from nltk.util, which is used to generate n-grams.\n","*   nltk.download('punkt'): This line downloads the punkt tokenizer models, which are used for splitting text into individual tokens (words)."],"metadata":{"id":"lTgDWIs2_E4p"}},{"cell_type":"markdown","source":["**Define a Function to Extract N-grams**"],"metadata":{"id":"Sfh82Vl4-6t1"}},{"cell_type":"code","source":["def extract_ngrams(data, num):\n","  n_grams = ngrams(nltk.word_tokenize(data),num)\n","  return [' '.join(grams) for grams in n_grams]"],"metadata":{"id":"vOamBfGKysiw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","*   def extract_ngrams(data, num): This defines a function named extract_ngrams that takes two parameters: data (the input text) and num (the number of words in each n-gram).\n","*   n_grams = ngrams(nltk.word_tokenize(data), num): This line tokenizes the input text into words using nltk.word_tokenize(data) and then generates n-grams of size num using the ngrams function.\n","*   return [' '.join(grams) for grams in n_grams]: This line joins the words in each n-gram into a single string and returns a list of these strings.\n","\n"],"metadata":{"id":"egMG6zmp_VE4"}},{"cell_type":"markdown","source":["**Define Input Text, and Extract and Print N-grams**"],"metadata":{"id":"4NVXusYf_jak"}},{"cell_type":"code","source":["my_text='I am interested in machine learning and deep learning .'\n","print(\"1-gram of the sample text:\", extract_ngrams(my_text,1), \"\\n\")\n","print(\"2-gram of the sample text:\", extract_ngrams(my_text,2), \"\\n\")\n","print(\"3-gram of the sample text:\", extract_ngrams(my_text,3), \"\\n\")\n","print(\"4-gram of the sample text:\", extract_ngrams(my_text,4), \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNLkuugdy5LL","executionInfo":{"status":"ok","timestamp":1720517406774,"user_tz":-360,"elapsed":4,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"c576193f-7265-4464-8818-b3a3eb2fb803"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1-gram of the sample text: ['I', 'am', 'interested', 'in', 'machine', 'learning', 'and', 'deep', 'learning', '.'] \n","\n","2-gram of the sample text: ['I am', 'am interested', 'interested in', 'in machine', 'machine learning', 'learning and', 'and deep', 'deep learning', 'learning .'] \n","\n","3-gram of the sample text: ['I am interested', 'am interested in', 'interested in machine', 'in machine learning', 'machine learning and', 'learning and deep', 'and deep learning', 'deep learning .'] \n","\n","4-gram of the sample text: ['I am interested in', 'am interested in machine', 'interested in machine learning', 'in machine learning and', 'machine learning and deep', 'learning and deep learning', 'and deep learning .'] \n","\n"]}]},{"cell_type":"markdown","source":["The above lines of code does the following actions:\n","\n","\n","1.   defines a string variable my_text containing the sample text to be analyzed.\n","2.   call the extract_ngrams function with different values for num (1 through 4) and print the resulting n-grams.\n","\n","\n","\n"],"metadata":{"id":"h4qk1eAZ_rn4"}},{"cell_type":"markdown","source":["**Summary**<br>\n","This notebook tokenizes the input text, generates n-grams of varying lengths, and prints them. It demonstrates how to use the nltk library to manipulate and analyze text data.\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"tjcrJDVYAUvW"}}]}