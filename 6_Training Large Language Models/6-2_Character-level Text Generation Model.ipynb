{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyORtVEqj02fRRo/zGFTLdGk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Import Libraries**"],"metadata":{"id":"gC-0ybj77glr"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Xaz8FwAXzdq1","executionInfo":{"status":"ok","timestamp":1720854765302,"user_tz":-360,"elapsed":6426,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"markdown","source":["Imports necessary libraries for data manipulation (numpy), deep learning (tensorflow), and text processing (tensorflow.keras.preprocessing.text and tensorflow.keras.preprocessing.sequence)."],"metadata":{"id":"Xi8kdqtk7h_B"}},{"cell_type":"markdown","source":["**Set Seed for Reproducibility**"],"metadata":{"id":"zbDmOljm7ku7"}},{"cell_type":"code","source":["tf.random.set_seed(42)"],"metadata":{"id":"ERJBHuRzz1mt","executionInfo":{"status":"ok","timestamp":1720854765302,"user_tz":-360,"elapsed":9,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Sets a seed for TensorFlow's random number generator to ensure reproducible results."],"metadata":{"id":"rhv52Lf97nxd"}},{"cell_type":"markdown","source":["**Input Text**"],"metadata":{"id":"CnhDtKnS7qx5"}},{"cell_type":"code","source":["input_text = '''\n","Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data.\n","It combines math and statistics, specialized programming, advanced analytics, artificial intelligence (AI) and machine learning with specific subject matter expertise to uncover actionable insights hidden in an organizationâ€™s data.\n","These insights can be used to guide decision making and strategic planning.\n","'''"],"metadata":{"id":"M6-eKGFlz5SK","executionInfo":{"status":"ok","timestamp":1720854765302,"user_tz":-360,"elapsed":8,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Defines the input text to be used for training the model."],"metadata":{"id":"tr9hquK27yIF"}},{"cell_type":"markdown","source":["**Character to Index Mapping**"],"metadata":{"id":"TkaXN7qK8Jyf"}},{"cell_type":"code","source":["chars = sorted(set(input_text))\n","char_to_idx = {char: idx for idx, char in enumerate(chars)}\n","idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n","num_chars = len(chars)"],"metadata":{"id":"qiruk8ay0XaC","executionInfo":{"status":"ok","timestamp":1720854765303,"user_tz":-360,"elapsed":9,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["*  Creates a set of unique characters in the input text and sorts them.\n","*  Creates dictionaries to map each character to an index and vice versa.\n","*  Determines the number of unique characters."],"metadata":{"id":"iApKsuIT8NrK"}},{"cell_type":"markdown","source":["**Prepare Input and Output Sequences**"],"metadata":{"id":"e-lxUTiD8W8F"}},{"cell_type":"code","source":["input_seq_length = 100\n","step = 1\n","input_sequences = []\n","output_chars = []\n","for i in range(0, len(input_text) - input_seq_length, step):\n","  input_seq = input_text[i: i + input_seq_length]\n","  output_seq = input_text[i + input_seq_length]\n","  input_sequences.append([char_to_idx[char] for char in input_seq])\n","  output_chars.append(char_to_idx[output_seq])\n","x = np.array(input_sequences)\n","y = to_categorical(output_chars, num_classes=num_chars)"],"metadata":{"id":"unuDMIxg73KT","executionInfo":{"status":"ok","timestamp":1720854765303,"user_tz":-360,"elapsed":9,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["*  Defines the length of input sequences and the step size for moving through the text.\n","*  Creates input sequences of length input_seq_length and corresponding output characters."],"metadata":{"id":"WX0lm0788Z0I"}},{"cell_type":"markdown","source":["**Convert Sequences to Arrays**"],"metadata":{"id":"2K-Wls148ecS"}},{"cell_type":"code","source":["x_one_hot = np.zeros((x.shape[0], input_seq_length, num_chars))\n","for i, seq in enumerate(x):\n","  for j, char in enumerate(seq):\n","    x_one_hot[i, j, char] = 1"],"metadata":{"id":"vUUf7VBr0rr0","executionInfo":{"status":"ok","timestamp":1720854765303,"user_tz":-360,"elapsed":9,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["*  Converts input sequences and output characters to numpy arrays.\n","*  One-hot encodes the input sequences to prepare them for training."],"metadata":{"id":"Z6dliH7p8hYZ"}},{"cell_type":"markdown","source":["**Define the Model**"],"metadata":{"id":"6WBwSaAQ8knw"}},{"cell_type":"code","source":["model = Sequential([\n","    LSTM(128, input_shape=(input_seq_length, num_chars)),\n","    Dense(num_chars, activation='softmax')\n","])"],"metadata":{"id":"ZEvXJ4DH1yle","executionInfo":{"status":"ok","timestamp":1720854766680,"user_tz":-360,"elapsed":1386,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Defines a sequential model with an LSTM layer followed by a Dense layer with a softmax activation."],"metadata":{"id":"827cN4Mt8msE"}},{"cell_type":"markdown","source":["**Compile the Model**"],"metadata":{"id":"f9v0C9We8o98"}},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='categorical_crossentropy')"],"metadata":{"id":"p0xwvrOo18fm","executionInfo":{"status":"ok","timestamp":1720854766681,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Compiles the model with the Adam optimizer and categorical crossentropy loss."],"metadata":{"id":"fyeCJNNv8rJk"}},{"cell_type":"markdown","source":["**Train the Model**"],"metadata":{"id":"XX9FJ4tn8ts6"}},{"cell_type":"code","source":["epochs = 100\n","batch_size = 64\n","model.fit(x_one_hot, y, epochs = epochs, batch_size = batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2I8CMIJc2BuU","executionInfo":{"status":"ok","timestamp":1720854775125,"user_tz":-360,"elapsed":8448,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"5606aaf6-7466-407a-806f-ef63123e90b4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","7/7 [==============================] - 2s 13ms/step - loss: 3.5920\n","Epoch 2/100\n","7/7 [==============================] - 0s 11ms/step - loss: 3.3964\n","Epoch 3/100\n","7/7 [==============================] - 0s 11ms/step - loss: 3.0831\n","Epoch 4/100\n","7/7 [==============================] - 0s 9ms/step - loss: 3.0164\n","Epoch 5/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.9966\n","Epoch 6/100\n","7/7 [==============================] - 0s 9ms/step - loss: 2.9915\n","Epoch 7/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.9799\n","Epoch 8/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.9814\n","Epoch 9/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.9742\n","Epoch 10/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.9627\n","Epoch 11/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.9602\n","Epoch 12/100\n","7/7 [==============================] - 0s 6ms/step - loss: 2.9587\n","Epoch 13/100\n","7/7 [==============================] - 0s 6ms/step - loss: 2.9540\n","Epoch 14/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.9485\n","Epoch 15/100\n","7/7 [==============================] - 0s 6ms/step - loss: 2.9454\n","Epoch 16/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.9342\n","Epoch 17/100\n","7/7 [==============================] - 0s 6ms/step - loss: 2.9296\n","Epoch 18/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.9250\n","Epoch 19/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.9139\n","Epoch 20/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.9056\n","Epoch 21/100\n","7/7 [==============================] - 0s 9ms/step - loss: 2.9075\n","Epoch 22/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.8940\n","Epoch 23/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.8690\n","Epoch 24/100\n","7/7 [==============================] - 0s 6ms/step - loss: 2.8669\n","Epoch 25/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.8491\n","Epoch 26/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.8411\n","Epoch 27/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.8418\n","Epoch 28/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.8275\n","Epoch 29/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.8061\n","Epoch 30/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.7755\n","Epoch 31/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.7546\n","Epoch 32/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.7316\n","Epoch 33/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.7184\n","Epoch 34/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.6950\n","Epoch 35/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.6688\n","Epoch 36/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.6484\n","Epoch 37/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.6269\n","Epoch 38/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.5788\n","Epoch 39/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.5460\n","Epoch 40/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.5404\n","Epoch 41/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.5025\n","Epoch 42/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.4621\n","Epoch 43/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.4087\n","Epoch 44/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.3942\n","Epoch 45/100\n","7/7 [==============================] - 0s 6ms/step - loss: 2.4061\n","Epoch 46/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.3788\n","Epoch 47/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.3735\n","Epoch 48/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.2965\n","Epoch 49/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.2582\n","Epoch 50/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.2700\n","Epoch 51/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.2657\n","Epoch 52/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.2033\n","Epoch 53/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.1453\n","Epoch 54/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.1468\n","Epoch 55/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.1136\n","Epoch 56/100\n","7/7 [==============================] - 0s 8ms/step - loss: 2.0819\n","Epoch 57/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.0541\n","Epoch 58/100\n","7/7 [==============================] - 0s 7ms/step - loss: 2.0185\n","Epoch 59/100\n","7/7 [==============================] - 0s 6ms/step - loss: 1.9772\n","Epoch 60/100\n","7/7 [==============================] - 0s 7ms/step - loss: 1.9276\n","Epoch 61/100\n","7/7 [==============================] - 0s 7ms/step - loss: 1.9275\n","Epoch 62/100\n","7/7 [==============================] - 0s 7ms/step - loss: 1.9126\n","Epoch 63/100\n","7/7 [==============================] - 0s 7ms/step - loss: 1.8937\n","Epoch 64/100\n","7/7 [==============================] - 0s 8ms/step - loss: 1.8498\n","Epoch 65/100\n","7/7 [==============================] - 0s 7ms/step - loss: 1.8456\n","Epoch 66/100\n","7/7 [==============================] - 0s 7ms/step - loss: 1.8078\n","Epoch 67/100\n","7/7 [==============================] - 0s 7ms/step - loss: 1.7931\n","Epoch 68/100\n","7/7 [==============================] - 0s 11ms/step - loss: 1.7614\n","Epoch 69/100\n","7/7 [==============================] - 0s 9ms/step - loss: 1.7530\n","Epoch 70/100\n","7/7 [==============================] - 0s 10ms/step - loss: 1.6971\n","Epoch 71/100\n","7/7 [==============================] - 0s 12ms/step - loss: 1.6758\n","Epoch 72/100\n","7/7 [==============================] - 0s 10ms/step - loss: 1.6433\n","Epoch 73/100\n","7/7 [==============================] - 0s 12ms/step - loss: 1.6313\n","Epoch 74/100\n","7/7 [==============================] - 0s 9ms/step - loss: 1.5917\n","Epoch 75/100\n","7/7 [==============================] - 0s 9ms/step - loss: 1.5599\n","Epoch 76/100\n","7/7 [==============================] - 0s 8ms/step - loss: 1.5199\n","Epoch 77/100\n","7/7 [==============================] - 0s 8ms/step - loss: 1.4926\n","Epoch 78/100\n","7/7 [==============================] - 0s 7ms/step - loss: 1.4777\n","Epoch 79/100\n","7/7 [==============================] - 0s 7ms/step - loss: 1.4790\n","Epoch 80/100\n","7/7 [==============================] - 0s 7ms/step - loss: 1.4833\n","Epoch 81/100\n","7/7 [==============================] - 0s 11ms/step - loss: 1.4325\n","Epoch 82/100\n","7/7 [==============================] - 0s 11ms/step - loss: 1.4233\n","Epoch 83/100\n","7/7 [==============================] - 0s 9ms/step - loss: 1.4297\n","Epoch 84/100\n","7/7 [==============================] - 0s 9ms/step - loss: 1.3783\n","Epoch 85/100\n","7/7 [==============================] - 0s 13ms/step - loss: 1.3183\n","Epoch 86/100\n","7/7 [==============================] - 0s 11ms/step - loss: 1.3115\n","Epoch 87/100\n","7/7 [==============================] - 0s 10ms/step - loss: 1.2782\n","Epoch 88/100\n","7/7 [==============================] - 0s 11ms/step - loss: 1.2771\n","Epoch 89/100\n","7/7 [==============================] - 0s 10ms/step - loss: 1.2471\n","Epoch 90/100\n","7/7 [==============================] - 0s 9ms/step - loss: 1.2030\n","Epoch 91/100\n","7/7 [==============================] - 0s 8ms/step - loss: 1.1741\n","Epoch 92/100\n","7/7 [==============================] - 0s 8ms/step - loss: 1.1488\n","Epoch 93/100\n","7/7 [==============================] - 0s 8ms/step - loss: 1.1470\n","Epoch 94/100\n","7/7 [==============================] - 0s 9ms/step - loss: 1.1251\n","Epoch 95/100\n","7/7 [==============================] - 0s 11ms/step - loss: 1.1335\n","Epoch 96/100\n","7/7 [==============================] - 0s 9ms/step - loss: 1.1159\n","Epoch 97/100\n","7/7 [==============================] - 0s 8ms/step - loss: 1.0603\n","Epoch 98/100\n","7/7 [==============================] - 0s 12ms/step - loss: 1.0498\n","Epoch 99/100\n","7/7 [==============================] - 0s 11ms/step - loss: 1.0101\n","Epoch 100/100\n","7/7 [==============================] - 0s 10ms/step - loss: 1.0026\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7f121757d3c0>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Trains the model for 100 epochs with a batch size of 64."],"metadata":{"id":"ahBOwsV08xGK"}},{"cell_type":"markdown","source":["**Generate Text Using the Trained Model**"],"metadata":{"id":"lOVB9haG8zp4"}},{"cell_type":"code","source":["def generate_text(model, seed_text, num_chars_to_generate = 100):\n","  generated_text = seed_text\n","  for _ in range(num_chars_to_generate):\n","    x_pred = np.zeros((1, input_seq_length, num_chars))\n","    for i, char in enumerate(generated_text[-input_seq_length:]):\n","      x_pred[0, i, char_to_idx[char]] = 1.0\n","    preds = model.predict(x_pred, verbose=0)[0]\n","    next_char_idx = np.argmax(preds)\n","    next_char = idx_to_char[next_char_idx]\n","    generated_text += next_char\n","  return generated_text\n",""],"metadata":{"id":"1pJ7kgz62MTb","executionInfo":{"status":"ok","timestamp":1720854775125,"user_tz":-360,"elapsed":4,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["*  Defines a function to generate text using the trained model.\n","*  Uses the seed text to generate a sequence of characters by predicting the next character iteratively."],"metadata":{"id":"2Fv8zUOL83IP"}},{"cell_type":"markdown","source":["**Generate and Print the Text**"],"metadata":{"id":"7L37yZ8B8-xb"}},{"cell_type":"code","source":["seed_text = \"Data Science is \"\n","generated_text = generate_text(model, seed_text, num_chars_to_generate = 200)\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MnBGvlSy3CZE","executionInfo":{"status":"ok","timestamp":1720854786981,"user_tz":-360,"elapsed":11860,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"d154cbc7-09cd-4a32-9265-578f731658b1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Data Science is  siiiiaaiiiiiiimmoaa a   im            sssiiimma       dddddda ttcaaa      s sssttststtte  xxxtrttt coollene end anights srticifis spect mante erterctrond antigts srcticiin  antiltinge t and ecticise \n"]}]},{"cell_type":"markdown","source":["*  Sets the seed text for text generation.\n","*  Generates a sequence of 200 characters starting from the seed text.\n","*  Prints the generated text."],"metadata":{"id":"v_bjYaMl9Bxb"}},{"cell_type":"markdown","source":["**Summary**<br>\n","The code trains a character-level language model using LSTM on a given input text. The trained model can then generate new text based on a seed input by predicting the next character iteratively."],"metadata":{"id":"XRSnqvNG9FSS"}},{"cell_type":"markdown","source":["**Reasons for Output Containing Garbage Characters**<br>\n","\n","\n","*   Limited Training Data\n","*   Struggling to Capture Long-range Dependencies\n","*   Lack of Contextual Understanding\n","\n"],"metadata":{"id":"__x5DnMq9Jec"}},{"cell_type":"markdown","source":["**Ways to Improve Quality of Generated Text**<br>\n","\n","\n","*   Larger and Diverse Training Dataset\n","*   Using Pre-trained Models\n","*   Implementing Sequence-to-sequence Models\n","*   Hyperparameter Tuning\n","*   Temperature Sampling\n","\n"],"metadata":{"id":"pR7EUVlE-and"}}]}