{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMBh+zSzb+BERYh1BTuWGmo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Install Required Libraries**"],"metadata":{"id":"Qjh2-MBEkdqt"}},{"cell_type":"code","source":["!pip install bertviz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KgoUQZ60hmsT","executionInfo":{"status":"ok","timestamp":1720764209870,"user_tz":-360,"elapsed":13250,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"f80a716d-9a27-46cb-969d-f23c3296e6bd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bertviz in /usr/local/lib/python3.10/dist-packages (1.4.0)\n","Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.41.2)\n","Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.3.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.66.4)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from bertviz) (1.34.143)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.31.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from bertviz) (2024.5.15)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bertviz) (0.1.99)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->bertviz) (12.5.82)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (6.0.1)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.4.3)\n","Requirement already satisfied: botocore<1.35.0,>=1.34.143 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (1.34.143)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (1.0.1)\n","Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->bertviz) (0.10.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2024.6.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.143->boto3->bertviz) (2.8.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->bertviz) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0->bertviz) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.143->boto3->bertviz) (1.16.0)\n"]}]},{"cell_type":"markdown","source":["This installs the bertviz library, which is used for visualizing attention in BERT models."],"metadata":{"id":"KRNQKdGQku2V"}},{"cell_type":"markdown","source":["Import Required Libraries"],"metadata":{"id":"-bFJyn17kw-z"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"zsl7eEy8f8Tx","executionInfo":{"status":"ok","timestamp":1720764212920,"user_tz":-360,"elapsed":3052,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"outputs":[],"source":["from bertviz import head_view, model_view\n","from transformers import BertTokenizer, BertModel"]},{"cell_type":"markdown","source":["*  head_view and model_view are visualization functions from bertviz.\n","*  BertTokenizer and BertModel are classes from the transformers library."],"metadata":{"id":"hB_gLIuPkzUE"}},{"cell_type":"markdown","source":["Load Pre-trained Model and Tokenizer"],"metadata":{"id":"VLvR-kcfk3_m"}},{"cell_type":"code","source":["model_version = 'bert-base-uncased'\n","model = BertModel.from_pretrained(model_version, output_attentions = True)\n","tokenizer = BertTokenizer.from_pretrained(model_version)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q40Oo5ZggSx3","executionInfo":{"status":"ok","timestamp":1720764215696,"user_tz":-360,"elapsed":2779,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"de26429e-e316-4655-ca4d-7818c61560ba"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["*  model_version specifies the pre-trained BERT model to use.\n","*  model = BertModel.from_pretrained(model_version, output_attentions = True) loads the BERT model with attention outputs.\n","*  tokenizer = BertTokenizer.from_pretrained(model_version) loads the tokenizer for the BERT model.  "],"metadata":{"id":"vZmOQvklk7vB"}},{"cell_type":"markdown","source":["**Define Input Sentences**"],"metadata":{"id":"hnAAzbePlCRU"}},{"cell_type":"code","source":["sentence1 = \"Peter loves animals, he likes cats more than dogs\"\n","sentence2 = \"He likes apples but hates oranges\""],"metadata":{"id":"OvPij-HTgetJ","executionInfo":{"status":"ok","timestamp":1720764215696,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**Tokenize the Input Sentences**"],"metadata":{"id":"51wlhpmVlHk1"}},{"cell_type":"code","source":["inputs = tokenizer.encode_plus(sentence1, sentence2, return_tensors = 'pt')\n","input_ids = inputs['input_ids']\n","token_type_ids = inputs['token_type_ids']"],"metadata":{"id":"HVRmPPpfgsrS","executionInfo":{"status":"ok","timestamp":1720764215697,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["*  inputs = tokenizer.encode_plus(sentence1, sentence2, return_tensors = 'pt') tokenizes the input sentences and returns them as PyTorch tensors ('pt').\n","*  input_ids contains the token IDs for both sentences.\n","*  token_type_ids distinguishes between the two sentences (0 for tokens in the first sentence, 1 for tokens in the second sentence)."],"metadata":{"id":"UuN6U3BIlKkr"}},{"cell_type":"markdown","source":["Get Model Attention Outputs, and Identify Sentence Boundaries and Convert Tokens"],"metadata":{"id":"yDlB0YrllTJX"}},{"cell_type":"code","source":["attention = model(input_ids, token_type_ids = token_type_ids)[-1]\n","sentence2_start = token_type_ids[0].tolist().index(1)\n","input_ids_list = input_ids[0].tolist()\n","tokens = tokenizer.convert_ids_to_tokens(input_ids_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOwqg7gshDHy","executionInfo":{"status":"ok","timestamp":1720764215697,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"b22c1cc5-24a9-440f-ee46-1c3a1f62f753"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"]}]},{"cell_type":"markdown","source":["*  attention stores the attention weights from the model.\n","*  sentence2_start finds the index where the second sentence starts.\n","*  input_ids_list converts the token IDs tensor to a list.\n","*  tokens converts the token IDs back to their corresponding tokens."],"metadata":{"id":"7Pt8nRtElacc"}},{"cell_type":"markdown","source":["**Visualize Attention Heads**"],"metadata":{"id":"SHUVKxaHlkXd"}},{"cell_type":"code","source":["head_view(attention, tokens, sentence2_start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520,"output_embedded_package_id":"1k-s7PJrfZTQ9llGBfrK8EcL95n27ScsB"},"id":"FiYkD0RLhZWD","executionInfo":{"status":"ok","timestamp":1720764220992,"user_tz":-360,"elapsed":5299,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"62a6cb5b-2f2d-43bb-e0dc-7b628add6ad4"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["head_view visualizes the attention heads using the attention weights, tokens, and the starting index of the second sentence."],"metadata":{"id":"Zk-rKo92loiJ"}},{"cell_type":"markdown","source":["**Summary**<br>\n","This code demonstrates how to:\n","*  Load a pre-trained BERT model and its tokenizer.\n","*  Tokenize and encode two input sentences.\n","*  Extract the attention weights from the model.\n","*  Identify the token positions for visualization.\n","*  Visualize the attention heads using bertviz.\n","\n","The head_view function from bertviz provides an interactive visualization of the attention weights, showing how the model attends to different tokens in the input sentences."],"metadata":{"id":"TOIeVGsblrTh"}}]}