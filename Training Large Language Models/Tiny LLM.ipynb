{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSINv5S3of61haNDrwkffo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Import Necessary Libraries**"],"metadata":{"id":"OUceB9K4ySVp"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"tAZnJlu5ttrr","executionInfo":{"status":"ok","timestamp":1720852043003,"user_tz":-360,"elapsed":814,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"outputs":[],"source":["from collections import defaultdict"]},{"cell_type":"markdown","source":["Imports defaultdict from the collections module. defaultdict is a dictionary-like container that provides default values for missing keys."],"metadata":{"id":"_eJh5P89yUAy"}},{"cell_type":"markdown","source":["**Function to Compute Bigram Probabilities**"],"metadata":{"id":"dZDepsGeyXhm"}},{"cell_type":"code","source":["def compute_bigram_probabilities(corpus):\n","  bigram_counts = defaultdict(lambda: defaultdict(int))\n","  for sentence in corpus:\n","    words = sentence.split()\n","    for i in range(len(words)-1):\n","      current_word = words[i]\n","      next_word = words[i+1]\n","      bigram_counts[current_word][next_word] += 1\n","  bigram_probabilities = defaultdict(lambda: defaultdict(float))\n","  for current_word, next_words in bigram_counts.items():\n","    total_count = sum(next_words.values())\n","    for next_word, count in next_words.items():\n","      bigram_probabilities[current_word][next_word] = count / total_count\n","  return bigram_probabilities"],"metadata":{"id":"hy71llSAt2fN","executionInfo":{"status":"ok","timestamp":1720852043003,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["*  Initializes bigram_counts as a nested defaultdict of integers to store the count of each bigram.\n","*  Splits each sentence into words and iterates over the words to count occurrences of each bigram.\n","*  Initializes bigram_probabilities as a nested defaultdict of floats to store the probability of each bigram.\n","*  Calculates the probability of each bigram by dividing the count of a bigram by the total count of bigrams starting with the same current word."],"metadata":{"id":"WAiHt92NybO6"}},{"cell_type":"markdown","source":["**Define the Corpus**"],"metadata":{"id":"ql6-4Aiiyj2h"}},{"cell_type":"code","source":["corpus = [\"Peter is happy\", \"Anna is happy\", \"Anna is sad\", \"Anna is good\", \"Peter is happy to see his old friend\", \"Peter is sad that he did not do well in exam\", \"Peter is hungry\", \"Tomy is sad\", \"Alex is happy\", \"Tomy is good\"]"],"metadata":{"id":"_A8K2wzOusyN","executionInfo":{"status":"ok","timestamp":1720852043003,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Defines the corpus as a list of sentences."],"metadata":{"id":"6JFe-m2Qyne3"}},{"cell_type":"markdown","source":["**Compute Bigram Probabilities**"],"metadata":{"id":"N85G6WpGypdm"}},{"cell_type":"code","source":["bigram_probabilities = compute_bigram_probabilities(corpus)\n","print(\"Bigram Probabilities: \", bigram_probabilities)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxJD45qTvFRA","executionInfo":{"status":"ok","timestamp":1720852043003,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"4d9d27fe-a293-475a-a631-843fac03b809"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Bigram Probabilities:  defaultdict(<function compute_bigram_probabilities.<locals>.<lambda> at 0x7d799e906d40>, {'Peter': defaultdict(<class 'float'>, {'is': 1.0}), 'is': defaultdict(<class 'float'>, {'happy': 0.4, 'sad': 0.3, 'good': 0.2, 'hungry': 0.1}), 'Anna': defaultdict(<class 'float'>, {'is': 1.0}), 'happy': defaultdict(<class 'float'>, {'to': 1.0}), 'to': defaultdict(<class 'float'>, {'see': 1.0}), 'see': defaultdict(<class 'float'>, {'his': 1.0}), 'his': defaultdict(<class 'float'>, {'old': 1.0}), 'old': defaultdict(<class 'float'>, {'friend': 1.0}), 'sad': defaultdict(<class 'float'>, {'that': 1.0}), 'that': defaultdict(<class 'float'>, {'he': 1.0}), 'he': defaultdict(<class 'float'>, {'did': 1.0}), 'did': defaultdict(<class 'float'>, {'not': 1.0}), 'not': defaultdict(<class 'float'>, {'do': 1.0}), 'do': defaultdict(<class 'float'>, {'well': 1.0}), 'well': defaultdict(<class 'float'>, {'in': 1.0}), 'in': defaultdict(<class 'float'>, {'exam': 1.0}), 'Tomy': defaultdict(<class 'float'>, {'is': 1.0}), 'Alex': defaultdict(<class 'float'>, {'is': 1.0})})\n"]}]},{"cell_type":"markdown","source":["*  Computes the bigram probabilities using the compute_bigram_probabilities function.\n","*  Prints the bigram probabilities."],"metadata":{"id":"GTbuWXvFys12"}},{"cell_type":"markdown","source":["**Find Words with Highest and Lowest Probabilities for Each Word**"],"metadata":{"id":"5ZW-RtYwyxFQ"}},{"cell_type":"code","source":["highest_probabilities = {}\n","lowest_probabilities = {}\n","for current_word, next_words in bigram_probabilities.items():\n","  highest_probabilities[current_word] = max(next_words, key=next_words.get)\n","  lowest_probabilities[current_word] = min(next_words, key=next_words.get)"],"metadata":{"id":"1HExJzbXvJVp","executionInfo":{"status":"ok","timestamp":1720852043003,"user_tz":-360,"elapsed":4,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["*  Initializes dictionaries highest_probabilities and lowest_probabilities to store the words with the highest and lowest bigram probabilities for each word.\n","*  Iterates over the bigram probabilities and finds the word with the highest and lowest probability for each current word."],"metadata":{"id":"Y0s5k1Hoy1YV"}},{"cell_type":"markdown","source":["**Generate Sentences with Highest and Lowest Probabilities**"],"metadata":{"id":"cXOlJxjjy5H5"}},{"cell_type":"code","source":["prompt = \"Peter\"\n","hword = lword = prompt\n","hsentence = lsentence = prompt + \" \"\n","for _ in range(2):\n","  hword = highest_probabilities[hword]\n","  lword = lowest_probabilities[lword]\n","  hsentence += hword + \" \"\n","  lsentence += lword + \" \""],"metadata":{"id":"9HJ4bJnwv8II","executionInfo":{"status":"ok","timestamp":1720852043004,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["*  Sets the prompt word to \"Peter\".\n","*  Initializes hword and lword with the prompt word.\n","*  Initializes hsentence and lsentence with the prompt word followed by a space.\n","*  Generates a sentence by appending the word with the highest probability and the word with the lowest probability for each word in the sentence for two iterations."],"metadata":{"id":"Yzfk1SJcy7yW"}},{"cell_type":"markdown","source":["**Print Generated Sentences**"],"metadata":{"id":"vr6d5Nd3zAzn"}},{"cell_type":"code","source":["print(\"Highest-probability sentence: \",hsentence)\n","print(\"Lowest-probability sentence: \",lsentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YIskXDJwO6O","executionInfo":{"status":"ok","timestamp":1720852043004,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"14a5d569-d2d8-474c-f620-69fa6e17e13b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Highest-probability sentence:  Peter is happy \n","Lowest-probability sentence:  Peter is hungry \n"]}]},{"cell_type":"markdown","source":["Prints the sentences generated using the highest and lowest bigram probabilities."],"metadata":{"id":"dN7mXDd4zDw1"}},{"cell_type":"markdown","source":["**Summary**<br>\n","This code calculates bigram probabilities from a given corpus and uses these probabilities to generate sentences. The sentences are constructed by starting with a prompt word and appending the next word with the highest and lowest probabilities, respectively, for a specified number of iterations."],"metadata":{"id":"FhEwhqbxzGBH"}}]}