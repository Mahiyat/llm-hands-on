{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNsDNBzbVmfh1qJMfJSzuKi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Import Libraries**"],"metadata":{"id":"pnZmEkkMTTlg"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"XXpy_W76ARQu","executionInfo":{"status":"ok","timestamp":1720857109606,"user_tz":-360,"elapsed":5044,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, Embedding\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"markdown","source":["Imports necessary libraries for data manipulation (numpy), deep learning (tensorflow), and text processing (tensorflow.keras.preprocessing.text and tensorflow.keras.preprocessing.sequence)."],"metadata":{"id":"mDYo_UYUTVAs"}},{"cell_type":"markdown","source":["**Set Seed for Reproducibility**"],"metadata":{"id":"HBKPM4_lTXjn"}},{"cell_type":"code","source":["tf.random.set_seed(42)"],"metadata":{"id":"scMjqp0dAZa2","executionInfo":{"status":"ok","timestamp":1720857109606,"user_tz":-360,"elapsed":10,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Sets a seed for TensorFlow's random number generator to ensure reproducible results."],"metadata":{"id":"nB9eZkHXTbV1"}},{"cell_type":"markdown","source":["**Input Text**"],"metadata":{"id":"b2PqNmPQTdaQ"}},{"cell_type":"code","source":["input_text = '''\n","Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data.\n","It combines math and statistics, specialized programming, advanced analytics, artificial intelligence (AI) and machine learning with specific subject matter expertise to uncover actionable insights hidden in an organizationâ€™s data.\n","These insights can be used to guide decision making and strategic planning.\n","'''"],"metadata":{"id":"UqcbkW64Abv-","executionInfo":{"status":"ok","timestamp":1720857109606,"user_tz":-360,"elapsed":9,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Defines the input text to be used for training the model."],"metadata":{"id":"kXx4vGmrTljG"}},{"cell_type":"markdown","source":["**Tokenization**"],"metadata":{"id":"vNWJtxmQTmfP"}},{"cell_type":"code","source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([input_text])"],"metadata":{"id":"vvXseZJTAeaf","executionInfo":{"status":"ok","timestamp":1720857109606,"user_tz":-360,"elapsed":9,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["*  Initializes a Tokenizer and fits it on the input text to create a word index.\n","*  Converts the input text into sequences of integers using the fitted tokenizer."],"metadata":{"id":"DarVBZs5ToeO"}},{"cell_type":"code","source":["num_words = len(tokenizer.word_index) + 1"],"metadata":{"id":"QWJlBOkRAklg","executionInfo":{"status":"ok","timestamp":1720857109606,"user_tz":-360,"elapsed":8,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["num_words gives the total number of unique words plus one (for padding)."],"metadata":{"id":"FJUBBuRWT1Cg"}},{"cell_type":"markdown","source":["**Prepare Input and Output Sequences**"],"metadata":{"id":"1JqiCNvGT6-y"}},{"cell_type":"code","source":["input_sequences = tokenizer.texts_to_sequences([input_text])\n","input_seq_length = 10\n","step = 1\n","x = []\n","y = []\n","for i in range(0, len(input_sequences[0])-input_seq_length, step):\n","  input_seq = input_sequences[0][i:i+input_seq_length]\n","  output_seq = input_sequences[0][i+input_seq_length]\n","  x.append(input_seq)\n","  y.append(output_seq)\n","x = np.array(x)\n","y = np.array(y)"],"metadata":{"id":"qq6awJ6BAplN","executionInfo":{"status":"ok","timestamp":1720857109606,"user_tz":-360,"elapsed":8,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["*  Defines the length of input sequences and the step size for moving through the text.\n","*  Creates input sequences of length input_seq_length and corresponding output words."],"metadata":{"id":"OOZ6G9cqT-N_"}},{"cell_type":"markdown","source":["**Define the Model**"],"metadata":{"id":"Ydd_MuJYUCDn"}},{"cell_type":"code","source":["model = Sequential([\n","   Embedding(input_dim = num_words, output_dim = 100, input_length = input_seq_length),\n","   LSTM(128),\n","   Dense(num_words, activation='softmax')\n","])"],"metadata":{"id":"kn8CdEWwBBIk","executionInfo":{"status":"ok","timestamp":1720857111060,"user_tz":-360,"elapsed":1462,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Defines a sequential model with:\n","*  An Embedding layer to convert input sequences into dense vectors of fixed size.\n","*  An LSTM layer with 128 units.\n","*  A Dense layer with a softmax activation to output probabilities for each word."],"metadata":{"id":"hJz_icXyUEID"}},{"cell_type":"markdown","source":["**Compile the Model**"],"metadata":{"id":"b6M_MLpPUJce"}},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"],"metadata":{"id":"Tbhn204DBWhr","executionInfo":{"status":"ok","timestamp":1720857111060,"user_tz":-360,"elapsed":3,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Compiles the model with the Adam optimizer and sparse categorical cross-entropy loss."],"metadata":{"id":"-Ra7YlOBUL7U"}},{"cell_type":"markdown","source":["**Train the Model**"],"metadata":{"id":"y07lW1qaUOEB"}},{"cell_type":"code","source":["epochs = 100\n","batch_size = 64\n","model.fit(x, y, epochs = epochs, batch_size = batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"swr1VucfBaqq","executionInfo":{"status":"ok","timestamp":1720857115876,"user_tz":-360,"elapsed":4819,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"a4eada75-7b2e-47ad-8d9b-daff8878faac"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 [==============================] - 3s 3s/step - loss: 4.0074\n","Epoch 2/100\n","1/1 [==============================] - 0s 12ms/step - loss: 4.0012\n","Epoch 3/100\n","1/1 [==============================] - 0s 10ms/step - loss: 3.9948\n","Epoch 4/100\n","1/1 [==============================] - 0s 10ms/step - loss: 3.9883\n","Epoch 5/100\n","1/1 [==============================] - 0s 9ms/step - loss: 3.9813\n","Epoch 6/100\n","1/1 [==============================] - 0s 9ms/step - loss: 3.9739\n","Epoch 7/100\n","1/1 [==============================] - 0s 11ms/step - loss: 3.9657\n","Epoch 8/100\n","1/1 [==============================] - 0s 9ms/step - loss: 3.9565\n","Epoch 9/100\n","1/1 [==============================] - 0s 9ms/step - loss: 3.9462\n","Epoch 10/100\n","1/1 [==============================] - 0s 10ms/step - loss: 3.9343\n","Epoch 11/100\n","1/1 [==============================] - 0s 10ms/step - loss: 3.9205\n","Epoch 12/100\n","1/1 [==============================] - 0s 9ms/step - loss: 3.9042\n","Epoch 13/100\n","1/1 [==============================] - 0s 9ms/step - loss: 3.8846\n","Epoch 14/100\n","1/1 [==============================] - 0s 10ms/step - loss: 3.8610\n","Epoch 15/100\n","1/1 [==============================] - 0s 10ms/step - loss: 3.8322\n","Epoch 16/100\n","1/1 [==============================] - 0s 10ms/step - loss: 3.7970\n","Epoch 17/100\n","1/1 [==============================] - 0s 9ms/step - loss: 3.7544\n","Epoch 18/100\n","1/1 [==============================] - 0s 11ms/step - loss: 3.7048\n","Epoch 19/100\n","1/1 [==============================] - 0s 10ms/step - loss: 3.6536\n","Epoch 20/100\n","1/1 [==============================] - 0s 10ms/step - loss: 3.6181\n","Epoch 21/100\n","1/1 [==============================] - 0s 10ms/step - loss: 3.6174\n","Epoch 22/100\n","1/1 [==============================] - 0s 11ms/step - loss: 3.6048\n","Epoch 23/100\n","1/1 [==============================] - 0s 11ms/step - loss: 3.5617\n","Epoch 24/100\n","1/1 [==============================] - 0s 11ms/step - loss: 3.5103\n","Epoch 25/100\n","1/1 [==============================] - 0s 11ms/step - loss: 3.4664\n","Epoch 26/100\n","1/1 [==============================] - 0s 12ms/step - loss: 3.4310\n","Epoch 27/100\n","1/1 [==============================] - 0s 12ms/step - loss: 3.3985\n","Epoch 28/100\n","1/1 [==============================] - 0s 12ms/step - loss: 3.3635\n","Epoch 29/100\n","1/1 [==============================] - 0s 11ms/step - loss: 3.3235\n","Epoch 30/100\n","1/1 [==============================] - 0s 13ms/step - loss: 3.2780\n","Epoch 31/100\n","1/1 [==============================] - 0s 15ms/step - loss: 3.2277\n","Epoch 32/100\n","1/1 [==============================] - 0s 12ms/step - loss: 3.1732\n","Epoch 33/100\n","1/1 [==============================] - 0s 17ms/step - loss: 3.1148\n","Epoch 34/100\n","1/1 [==============================] - 0s 12ms/step - loss: 3.0527\n","Epoch 35/100\n","1/1 [==============================] - 0s 11ms/step - loss: 2.9881\n","Epoch 36/100\n","1/1 [==============================] - 0s 14ms/step - loss: 2.9235\n","Epoch 37/100\n","1/1 [==============================] - 0s 13ms/step - loss: 2.8604\n","Epoch 38/100\n","1/1 [==============================] - 0s 15ms/step - loss: 2.7972\n","Epoch 39/100\n","1/1 [==============================] - 0s 10ms/step - loss: 2.7328\n","Epoch 40/100\n","1/1 [==============================] - 0s 11ms/step - loss: 2.6702\n","Epoch 41/100\n","1/1 [==============================] - 0s 13ms/step - loss: 2.6095\n","Epoch 42/100\n","1/1 [==============================] - 0s 12ms/step - loss: 2.5461\n","Epoch 43/100\n","1/1 [==============================] - 0s 10ms/step - loss: 2.4812\n","Epoch 44/100\n","1/1 [==============================] - 0s 13ms/step - loss: 2.4194\n","Epoch 45/100\n","1/1 [==============================] - 0s 13ms/step - loss: 2.3565\n","Epoch 46/100\n","1/1 [==============================] - 0s 15ms/step - loss: 2.2905\n","Epoch 47/100\n","1/1 [==============================] - 0s 13ms/step - loss: 2.2252\n","Epoch 48/100\n","1/1 [==============================] - 0s 12ms/step - loss: 2.1584\n","Epoch 49/100\n","1/1 [==============================] - 0s 11ms/step - loss: 2.0900\n","Epoch 50/100\n","1/1 [==============================] - 0s 14ms/step - loss: 2.0250\n","Epoch 51/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.9639\n","Epoch 52/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.9077\n","Epoch 53/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.8527\n","Epoch 54/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.7966\n","Epoch 55/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.7418\n","Epoch 56/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.6858\n","Epoch 57/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.6296\n","Epoch 58/100\n","1/1 [==============================] - 0s 13ms/step - loss: 1.5731\n","Epoch 59/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.5182\n","Epoch 60/100\n","1/1 [==============================] - 0s 17ms/step - loss: 1.4652\n","Epoch 61/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.4135\n","Epoch 62/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.3647\n","Epoch 63/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.3190\n","Epoch 64/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.2750\n","Epoch 65/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.2317\n","Epoch 66/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.1900\n","Epoch 67/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.1507\n","Epoch 68/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.1122\n","Epoch 69/100\n","1/1 [==============================] - 0s 14ms/step - loss: 1.0747\n","Epoch 70/100\n","1/1 [==============================] - 0s 12ms/step - loss: 1.0389\n","Epoch 71/100\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0039\n","Epoch 72/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.9689\n","Epoch 73/100\n","1/1 [==============================] - 0s 16ms/step - loss: 0.9351\n","Epoch 74/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.9030\n","Epoch 75/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.8710\n","Epoch 76/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.8392\n","Epoch 77/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.8097\n","Epoch 78/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.7816\n","Epoch 79/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.7537\n","Epoch 80/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.7271\n","Epoch 81/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.7000\n","Epoch 82/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6738\n","Epoch 83/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6489\n","Epoch 84/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6246\n","Epoch 85/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.6018\n","Epoch 86/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.5786\n","Epoch 87/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.5563\n","Epoch 88/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.5338\n","Epoch 89/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.5129\n","Epoch 90/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.4935\n","Epoch 91/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4754\n","Epoch 92/100\n","1/1 [==============================] - 0s 13ms/step - loss: 0.4578\n","Epoch 93/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.4416\n","Epoch 94/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.4255\n","Epoch 95/100\n","1/1 [==============================] - 0s 14ms/step - loss: 0.4106\n","Epoch 96/100\n","1/1 [==============================] - 0s 10ms/step - loss: 0.3962\n","Epoch 97/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3825\n","Epoch 98/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3693\n","Epoch 99/100\n","1/1 [==============================] - 0s 12ms/step - loss: 0.3560\n","Epoch 100/100\n","1/1 [==============================] - 0s 11ms/step - loss: 0.3434\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7f460238f070>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Trains the model for 100 epochs with a batch size of 64."],"metadata":{"id":"XO4OhZLNUQ50"}},{"cell_type":"markdown","source":["**Generate Text Using the Trained Model**"],"metadata":{"id":"xHYW-gsiUTDC"}},{"cell_type":"code","source":["def generate_text(model, seed_text, num_words_to_generate=50):\n","  generated_text = seed_text\n","  for _ in range(num_words_to_generate):\n","      input_seq = tokenizer.texts_to_sequences([generated_text])[0]\n","      input_seq = pad_sequences([input_seq], maxlen=input_seq_length, padding='pre')\n","\n","      preds = model.predict(input_seq)[0]\n","      next_word_idx = np.argmax(preds)\n","      next_word = tokenizer.index_word[next_word_idx]\n","      generated_text += \" \" + next_word\n","  return generated_text"],"metadata":{"id":"TYK--8tZCYWz","executionInfo":{"status":"ok","timestamp":1720857115876,"user_tz":-360,"elapsed":5,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["*  Defines a function to generate text using the trained model.\n","*  Uses the seed text to generate a sequence of words by predicting the next word iteratively.\n","*  Converts the generated text to sequences and pads them to match the input sequence length.\n","*  Uses the model to predict the next word, appends it to the generated text, and repeats for the specified number of words."],"metadata":{"id":"GmW8K7ADUWCh"}},{"cell_type":"markdown","source":["**Generate and Print the Text**"],"metadata":{"id":"KX4mPCTTUcJ2"}},{"cell_type":"code","source":["seed_text = \"Data science is\"\n","generated_text = generate_text(model, seed_text, num_words_to_generate=50)\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82RleR9kCaDX","executionInfo":{"status":"ok","timestamp":1720857119120,"user_tz":-360,"elapsed":3249,"user":{"displayName":"Mahiyat Tanzim","userId":"03004994999431640800"}},"outputId":"55f20852-d455-4362-c8c6-478f41d104f9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 425ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","Data science is matter matter matter matter to to to to in insights data data these insights insights insights insights be planning and and and unstructured data data it and and advanced advanced advanced advanced and and and analytics and and ai ai and and and and and artificial and and and and\n"]}]},{"cell_type":"markdown","source":["*  Sets the seed text for text generation.\n","*  Generates a sequence of 50 words starting from the seed text.\n","*  Prints the generated text."],"metadata":{"id":"5JcNWisyUfd5"}},{"cell_type":"markdown","source":["**Summary**<br>\n","The code trains a word-level language model using LSTM on a given input text. The trained model can then generate new text based on a seed input by predicting the next word iteratively. The model is designed to handle sequences of 10 words and uses an embedding layer to convert words into dense vectors before feeding them into the LSTM layer."],"metadata":{"id":"DE7nWMWEUkwc"}},{"cell_type":"markdown","source":["**Note**<br>\n","For better results, more extensive and diverse training data and more advanced language models like GPT or BERT can be used."],"metadata":{"id":"jkX1nBcTU74q"}}]}