{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pre-requisite\n",
    "**Setup Ollama**<br>\n",
    "For setting up ollama in your local environment, click [here](https://github.com/ollama/ollama).\n",
    "\n",
    "**Pull Model**<br>\n",
    "Pull the required model running the following command:\n",
    "```bash\n",
    "ollama pull llama3.2\n",
    "```\n",
    "To use more variants of the llama model check [here](https://ollama.com/library).\n",
    "\n",
    "**Install python library**<br>\n",
    "Install the python library for ollama\n",
    "```bash\n",
    "pip install ollama\n",
    "```\n",
    "To learn more, click [here](https://github.com/ollama/ollama-python)."
   ],
   "id": "609339a34430b01e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "154a76483759757e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-11T12:43:16.994518Z",
     "start_time": "2024-10-11T12:43:16.672205Z"
    }
   },
   "source": [
    "import ollama\n",
    "from IPython.display import display, Markdown\n",
    "from numpy import random"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* ollama: This library allows you to interact with models hosted by Ollama (e.g., the llama3.2 model). It supports sending messages and receiving responses from the model.\n",
    "* IPython.display: The display function and Markdown module are used to format and display the modelâ€™s response as formatted markdown in a Jupyter/IPython environment.\n",
    "* numpy.random: This is used for generating random numbers and controlling randomness in code execution."
   ],
   "id": "9312e59e9f65ec3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setting a Random Seed",
   "id": "c7313e860a91f465"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T12:43:17.010297Z",
     "start_time": "2024-10-11T12:43:17.000214Z"
    }
   },
   "cell_type": "code",
   "source": "random.seed(42)",
   "id": "d521cd47b72f166",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This sets a seed for reproducibility in any random number generation used within the code. Though not directly related to the model, it ensures the random processes (if any) are repeatable.",
   "id": "5a5fee45d4909a38"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Making the First Request to Ollama's Llama Model",
   "id": "e4ec2a334b9743cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T12:43:41.861016Z",
     "start_time": "2024-10-11T12:43:17.073965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response1 = ollama.chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Tell me about Machine Learning.',\n",
    "  },\n",
    "])\n",
    "display(Markdown(response1['message']['content']))"
   ],
   "id": "c35d9a2fd01fb9f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that involves training algorithms to learn from data and improve their performance on specific tasks without being explicitly programmed.\n\n**Key Components of Machine Learning:**\n\n1. **Training Data**: A dataset used to train the algorithm, which consists of examples or instances of the problem you want to solve.\n2. **Model**: The algorithm itself, such as a neural network or decision tree, that learns from the training data.\n3. **Error Function**: A measure of how well the model is performing on the training data, used to optimize the model's parameters.\n\n**Types of Machine Learning:**\n\n1. **Supervised Learning**: The algorithm is trained on labeled data (data with a target output), where it learns to map inputs to outputs.\n2. **Unsupervised Learning**: The algorithm is trained on unlabeled data, and it discovers patterns or relationships in the data on its own.\n3. **Reinforcement Learning**: The algorithm learns by interacting with an environment, receiving feedback in the form of rewards or penalties.\n\n**Machine Learning Applications:**\n\n1. **Image Recognition**: Object detection, facial recognition, image classification\n2. **Natural Language Processing (NLP)**: Text analysis, sentiment analysis, language translation\n3. **Predictive Analytics**: Predicting customer behavior, credit risk assessment, demand forecasting\n4. **Recommendation Systems**: Personalized product recommendations, content filtering\n\n**Machine Learning Workflow:**\n\n1. **Data Preparation**: Cleaning, preprocessing, and transforming the data for training.\n2. **Model Selection**: Choosing a suitable algorithm or model based on the problem type and data characteristics.\n3. **Training**: Training the model on the prepared data.\n4. **Validation**: Evaluating the model's performance on a separate test dataset.\n5. **Deployment**: Deploying the trained model in production, either as a standalone application or integrated with other systems.\n\n**Challenges and Limitations:**\n\n1. **Data Quality and Availability**: Insufficient or noisy data can lead to suboptimal results.\n2. **Overfitting**: The model becomes too specialized to the training data and fails to generalize well.\n3. **Interpretability**: Understanding how the model arrived at its decisions can be challenging.\n\n**Real-World Applications of Machine Learning:**\n\n1. **Autonomous Vehicles**: Self-driving cars, drones, and robots use ML for perception, prediction, and decision-making.\n2. **Healthcare**: Predictive modeling for disease diagnosis, patient risk assessment, and personalized medicine.\n3. **Customer Service Chatbots**: Conversational AI using NLP and ML to provide customer support.\n\nMachine Learning is a rapidly evolving field with many exciting applications and opportunities. Its potential to automate complex tasks and improve decision-making has made it an essential tool in various industries."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------\n",
    "**Explanation of Code**<br>\n",
    "* The ollama.chat() function sends a request to the llama3.2 model with the prompt \"Tell me about Machine Learning.\".\n",
    "* The request is formatted as a list of messages. Here, a single message with the user's role is sent.\n",
    "* The model responds with information about Machine Learning.\n",
    "* The response is displayed using IPython's Markdown display, formatting the text nicely within the notebook interface."
   ],
   "id": "5803e5e91af2dbc6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Making the Second Request to Ollama's Llama Model with Streaming",
   "id": "8b1dd5de4c3cafd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T12:43:49.745406Z",
     "start_time": "2024-10-11T12:43:41.878018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response2 = ollama.chat(\n",
    "  model='llama3.2', \n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'What is Large Language Model?',\n",
    "    },],\n",
    "  stream=True\n",
    ")\n",
    "for chunk in response2:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ],
   "id": "a9882c456a871828",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model (LLM) is a type of artificial intelligence (AI) model that is specifically designed to process and understand human language. LLMs are trained on massive amounts of text data, which enables them to learn patterns, relationships, and nuances of language.\n",
      "\n",
      "LLMs use various techniques such as natural language processing (NLP), deep learning, and transformer architecture to analyze and generate text. They can be used for a wide range of applications, including:\n",
      "\n",
      "1. **Language Translation**: LLMs can translate languages in real-time, allowing people to communicate across language barriers.\n",
      "2. **Text Generation**: LLMs can generate human-like text based on a prompt or input, such as articles, stories, and conversations.\n",
      "3. **Sentiment Analysis**: LLMs can analyze the sentiment and emotions expressed in text, enabling applications like customer service chatbots and social media monitoring.\n",
      "4. **Question Answering**: LLMs can answer questions based on their understanding of the text they were trained on.\n",
      "5. **Chatbots and Virtual Assistants**: LLMs power conversational interfaces for companies, allowing customers to interact with them in a more human-like way.\n",
      "\n",
      "Characteristics of Large Language Models:\n",
      "\n",
      "1. **Massive Training Data**: LLMs are trained on enormous amounts of text data, often in the billions or even trillions of parameters.\n",
      "2. **Complex Architecture**: LLMs use advanced neural network architectures, such as transformer models, to analyze and generate text.\n",
      "3. **Self-Supervised Learning**: LLMs learn through self-supervision techniques, where they generate text based on their understanding of the input data.\n",
      "4. **Scalability**: LLMs can be scaled up or down depending on the specific application and requirements.\n",
      "\n",
      "Examples of Large Language Models:\n",
      "\n",
      "1. **BERT (Bidirectional Encoder Representations from Transformers)**: Developed by Google, BERT is a pre-trained language model that has become widely used in NLP applications.\n",
      "2. **RoBERTa (Robustly Optimized BERT Pretraining Approach)**: Another popular pre-trained language model developed by Facebook AI Research.\n",
      "3. **Transformers**: A family of transformer-based models, including BERT and RoBERTa, which have become the standard for many NLP tasks.\n",
      "\n",
      "In summary, Large Language Models are powerful tools that can process and understand human language at scale. They have numerous applications across various industries and continue to evolve with advancements in AI and NLP research."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* A second request is made to the llama3.2 model, asking \"What is Large Language Model?\".\n",
    "* This time, the stream=True option is used, meaning the response is returned in chunks (real-time streaming).\n",
    "* The response is processed chunk-by-chunk. The for loop iterates over the streamed chunks, printing them to the console as soon as they are received. The end='' argument ensures that the content is printed continuously without adding extra newlines.\n",
    "* flush=True ensures the output is immediately flushed and shown to the user in real-time."
   ],
   "id": "6bbc1469beff5071"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "* The code interacts with the Llama model through the Ollama API.\n",
    "* It sends two prompts and displays the responses: one in markdown format and another using streaming output.\n",
    "* The stream=True option demonstrates how to handle real-time responses from the model."
   ],
   "id": "a185d81e9dcf884e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
